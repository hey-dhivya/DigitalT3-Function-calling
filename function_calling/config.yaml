llm: 
  "api": "sncloud" #  set either sambastudio or sncloud
  "do_sample": False
  "temperature": 0.0
  "max_tokens_to_generate": 1024
  "coe": True #set as true if using Sambastudio CoE endpoint
  "select_expert": "llama3-405b" #set if using sncloud, SambaStudio CoE llm expert
        #sncloud CoE expert name -> "llama3-405b"

tools:
    query_db:
      llm: 
        "api": "sncloud" #  set either sambastudio or sncloud
        "do_sample": False
        "temperature": 0.0 
        "max_tokens_to_generate": 1024
        "coe": True #set as true if using Sambastudio CoE endpoint
        "select_expert": "llama3-405b" #set if using sncloud, SambaStudio CoE llm expert
        #sncloud CoE expert name -> "llama3-405b"
      db:
        "path": "data/chinook.db" 

    translate:
      llm: 
        "api": "sncloud" #  set either sambastudio or sncloud
        "do_sample": False
        "temperature": 0.0
        "max_tokens_to_generate": 1024
        "coe": True #set as true if using Sambastudio CoE endpoint
        "select_expert": "llama3-405b" #set if using sncloud, SambaStudio CoE llm expert
        #sncloud CoE expert name -> "llama3-405b"

    rag:
      llm:
        "api": "sncloud" #  set either sambastudio or sncloud
        "do_sample": False
        "temperature": 0.0 
        "max_tokens_to_generate": 1024
        "coe": True #set as true if using Sambastudio CoE endpoint
        "select_expert": "llama3-405b" #set if using sncloud, SambaStudio CoE llm expert
        #sncloud CoE expert name -> "llama3-405b"
      embedding_model: 
        "type": "cpu" # set either sambastudio or cpu
        "batch_size": 1 #set depending of your endpoint configuration (1 if CoE embedding expert)
        "coe": True #set true if using Sambastudio embeddings in a CoE endpoint 
        "select_expert": "e5-mistral-7b-instruct" #set if using SambaStudio CoE embedding expert
      vector_db:
        "path": "data/my-vector-db" # path to your previously created chroma vdb
      retrieval:
        "k_retrieved_documents": 3
        "score_treshold": 0.3

prod_mode: False